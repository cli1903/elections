---
title: "R Notebook"
output: html_notebook
---

library(randomForest)
library(tree)
library(e1071)
library(class)
library(xgboost)


train_data = read.table('/Users/cindyli/Documents/php2650/final/data/primary_training_inputs_r.csv', sep = ',', header = TRUE)

test_data = read.table('/Users/cindyli/Documents/php2650/final/data/primary_testing_inputs_r.csv', sep = ',', header = TRUE)

num_counties = dim(train_data)[1]

set.seed(1)
shuffle_indices = sample(c(1:num_counties))

train = train_data[shuffle_indices, ]

tr = tree(as.factor(winner)~., data = train)
set.seed(1)
tr.cv = cv.tree(tr)
plot(tr.cv$size, tr.cv$deviance)
plot(tr.cv$k, tr.cv$deviance)
tr.pred = predict(tr, newdata = test_data, type = 'class')
tr.accuracy = mean(1 * (tr.pred == test_data$winner))
tr.train.pred = predict(tr, newdata = train, type = 'class')
tr.train.acc = mean(ifelse(tr.train.pred == train$winner, 1, 0))


set.seed(1)
rf = randomForest(as.factor(winner)~., data = train, importance = TRUE)
rf.pred = predict(rf, newdata = test_data, type = 'class')
rf.accuracy = mean(1 * (rf.pred == test_data$winner))
rf.train.pred = predict(rf, newdata = train, type = 'class')
rf.train.acc = mean(ifelse(rf.train.pred == train$winner, 1, 0))
varImpPlot(rf)

svmr = svm(as.factor(winner)~., data = train, kernel="radial")
svmr.pred = predict(svmr, newdata = test_data, type = 'class')
svmr.accuracy = mean(1 * (svmr.pred == test_data$winner))
svmr.train.pred = predict(svmr, newdata = train, type = 'class')
svmr.train.acc = mean(ifelse(svmr.train.pred == train$winner, 1, 0))

set.seed(1)
svmr.tune = tune(svm, as.factor(winner)~.-, data = train, kernel = "radial", ranges = list(cost = c(0.1,1,10,100,1000), gamma = c(0.5,1,2,3,4)))



kn = knn(train[, -53], test_data[, -53], cl = train$winner, k = 5)
kn.acc = mean(ifelse(kn == test_data$winner, 1, 0))

kn_train = knn(train[, -53], train[, -53], cl = train$winner, k = 5)
kn.train.acc = mean(1 * (kn_train == train$winner))

train_matrix = xgb.DMatrix(label = train$winner, data = model.matrix(winner~., train))
xgb = xgboost(data = train_matrix, label = train$winner, nrounds = 3)



